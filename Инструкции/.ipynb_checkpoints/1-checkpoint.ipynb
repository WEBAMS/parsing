{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3716b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка необходимых библиотек через терминал:\n",
    "\n",
    "pip install requests\n",
    "pip install beautifulsoup4\n",
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002795cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Парсить будем с сайтов:\n",
    "https://quotes.toscrape.com/\n",
    "https://scrapingclub.com/exercise/list_basic/?page=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2188b6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем в проекте файл питона с любым названием - qwe.py\n",
    "# Импортируем в него библиотеки:\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef7e6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Открывает сайт, с которого будем парсить информацию. Правой кнопкой мыши вызываем \"Посмотреть код(Инспектировать элемент)\".\n",
    "# Нужно найти в HTML коде, что объединяет описание товаров(или другую нужную нам информацию).\n",
    "\n",
    "# Копируем адрес страницы сайта\n",
    "# Создаем переменную и присваиваем ей этот адрес\n",
    "\n",
    "url = \"https://scrapingclub.com/exercise/list_basic/?page=1\"\n",
    "\n",
    "# Создаем переменную, куда будем получать ответ от сайта\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "# проверяем через корректность выполнения команду Print\n",
    "\n",
    "print(response.text) # ответ 200 означает правильное выполнение команды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6d8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем переменную и присываиваем ей класс BeautifulSoup с аргументами response.text и lxml(парсер)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'lxml') # html.parser - аналог lxml\n",
    "\n",
    "# Визуально можно посмотреть код сайта так:\n",
    "\n",
    "fl = open('proba.txt','w', encoding = 'utf-8') # Создаем переменную с командой создания файла .txt через метод 'w' - запись\n",
    "print(soup, file = fl) # Записываем в файл информацию с сайта, полученную с помощью команды response.text\n",
    "fl.close() # Закрываем файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0cb1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создадим еще одну переменную \n",
    "\n",
    "data = soup.find(\"div\") # Метод find возвращает информацию по указанному аргументу(например, тегу div)\n",
    "\n",
    "# Для конкретизации лучше указать дополнительный параметр, например класс этого тега:\n",
    "\n",
    "data = soup.find(\"div\", class_=\"w-full rounded border\")\n",
    "\n",
    "# Берем с сайта название товара\n",
    "\n",
    "name = data.find(\"h4\") # Дальнейшее уточнение по тегу H4\n",
    "\n",
    "name = data.find(\"h4\").text # Если нужно получить только текст, то добавляем атрибут text\n",
    "\n",
    "name = data.find(\"h4\").text.replace('\\n', '') # Применяем replace если нужно удалить какой-то символ, например знак переноса\n",
    "\n",
    "# Берем цену\n",
    "\n",
    "price = data.find(\"h5\").text\n",
    "\n",
    "# Берем ссылку на картинку товара с помощью метода get()\n",
    "# Метод get() позволяет получить информацию по атрибуту тега, например href или src\n",
    "\n",
    "url_img = data.find(\"img\", class_=\"card-img-top img-fluid\").get(\"src\")\n",
    "\n",
    "# Но мы скопировали только относительную ссылку(/static/img/90008-E.jpg). Нужно получить полный адрес.\n",
    "# Добавляем в переменную адрес сайта.\n",
    "\n",
    "url_img = \"https://scrapingclub.com\" + data.find(\"img\", class_=\"card-img-top img-fluid\").get(\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7228370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Собираем карточки всех товаров\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
